{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import librosa  \n",
    "import numpy as np  \n",
    "import os\n",
    "import random\n",
    "from librosa.effects import time_stretch, pitch_shift\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utliity Functions\n",
    "def extract_features(data, sample_rate=22050):\n",
    "\n",
    "    # Extracting features from the audio data\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(y=data, sr=sample_rate).T, axis=0)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    mel_spectrogram = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=data, sr=sample_rate).T, axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=data, sr=sample_rate).T, axis=0)\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=data, sr=sample_rate).T, axis=0)\n",
    "    poly_features = np.mean(librosa.feature.poly_features(y=data, sr=sample_rate).T, axis=0)\n",
    "\n",
    "    # Horizontally stacking features\n",
    "    features = np.hstack([zcr, chroma_stft, mfcc, rms, mel_spectrogram, spectral_contrast, tonnetz, spectral_rolloff, poly_features])\n",
    "\n",
    "    # Scaling features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features.reshape(-1, 1))\n",
    "\n",
    "    return scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a mapping from class names to integers\n",
    "class_map = {'Angry': 0, 'Disgusted': 1, 'Fearful': 2, 'Happy': 3, 'Neutral': 4, 'Sad': 5, 'Surprised': 6}\n",
    "\n",
    "# Defining the noise transformation function\n",
    "def noise(data, noise_factor=1.0):\n",
    "    noise_amp = 0.025*np.random.uniform()*np.amax(data) \n",
    "    data = data + noise_factor * noise_amp * np.random.normal(size=data.shape[0])  # adding random amount of gaussian noise for the entirety of the audio\n",
    "    return data\n",
    "\n",
    "\n",
    "# Making the generator function\n",
    "def data_generator(files, batch_size=32):\n",
    "    while True:\n",
    "        # Shuffling the list of files\n",
    "        random.shuffle(files)\n",
    "\n",
    "        # Applying transformations to each file and stack them\n",
    "        batch_data = []\n",
    "        batch_labels = []\n",
    "        for file in files:\n",
    "            # Loading the audio file\n",
    "            data, sr = librosa.load(file, sr=22050, res_type='kaiser_fast')\n",
    "\n",
    "            # Applying transformations with random intensities\n",
    "            data = time_stretch(data, rate = random.uniform(0.5, 1.5) )\n",
    "            data = pitch_shift(data, sr, n_steps = random.randint(-5, 5))\n",
    "            data = noise(data, noise_factor = random.uniform(0, 1.5)) \n",
    "\n",
    "            features = extract_features(data, sr=sr)\n",
    "\n",
    "            # Get the label from the file name\n",
    "            batch_data.append(features)\n",
    "            label = os.path.basename(os.path.dirname(file))\n",
    "            batch_labels.append(class_map[label])\n",
    "\n",
    "            # Yield batches\n",
    "            if len(batch_data) == batch_size:\n",
    "                yield np.array(batch_data), np.array(batch_labels)\n",
    "                batch_data = []\n",
    "                batch_labels = []\n",
    "        if batch_data:\n",
    "            yield np.array(batch_data), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = os.path.join(os.getcwd(), 'filtered_dataset')                \n",
    "# Get a list of all audio files in the directory\n",
    "all_files = []\n",
    "for subdir, dirs, files in os.walk(audio_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            all_files.append(os.path.join(subdir, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the list of files into training and test sets\n",
    "train_files, test_files = train_test_split(all_files, test_size=0.3, random_state=48)\n",
    "\n",
    "# Create generators for training and test sets\n",
    "train_generator = data_generator(train_files)\n",
    "test_generator = data_generator(test_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "input_shape = next(train_generator)[0].shape[1:]\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv1D(256, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Defining the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=14, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, validation_data=(test_generator), epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 4))\n",
    "\n",
    "# Plot training loss and validation loss\n",
    "ax1.plot(history.history['loss'], label='Training Loss')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot training accuracy and validation accuracy\n",
    "ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save('saved_model/model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the detection function\n",
    "def detect(audio_path):\n",
    "    features = extract_features(audio_path)\n",
    "    features = np.expand_dims(features, axis=0) # Adding a batch dimension\n",
    "    pred = model.predict(features) \n",
    "    pred_index = np.argmax(pred)\n",
    "    label = {v: k for k, v in class_map.items()}[pred_index] # reversing the class_map to fetch the label from the index\n",
    "    return label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "site_build_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
